{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aee6340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:37: SyntaxWarning: \"\\g\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\g\"? A raw string is also an option.\n",
      "<>:37: SyntaxWarning: \"\\g\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\g\"? A raw string is also an option.\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_37596\\525095009.py:37: SyntaxWarning: \"\\g\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\g\"? A raw string is also an option.\n",
      "  FILE_PATH = \"D:\\git_rk\\data\\survey.csv\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\git_rk\\.venv\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: pandas in d:\\git_rk\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\git_rk\\.venv\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: tqdm in d:\\git_rk\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dotenv in d:\\git_rk\\.venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\git_rk\\.venv\\lib\\site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\git_rk\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\git_rk\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\git_rk\\.venv\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\git_rk\\.venv\\lib\\site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in d:\\git_rk\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\git_rk\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\git_rk\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in d:\\git_rk\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\git_rk\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\git_rk\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\git_rk\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\git_rk\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\git_rk\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\git_rk\\.venv\\lib\\site-packages (from pandas) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\git_rk\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\git_rk\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\git_rk\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in d:\\git_rk\\.venv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in d:\\git_rk\\.venv\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in d:\\git_rk\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in d:\\git_rk\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\git_rk\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "총 3건 주관식 응답 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]2026-01-05 21:31:09,507 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-05 21:31:10,226 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 1/3 [00:15<00:31, 15.94s/it]2026-01-05 21:31:13,431 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 3/3 [00:19<00:00,  6.38s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]2026-01-05 21:31:30,063 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 33%|███▎      | 1/3 [00:16<00:33, 16.60s/it]2026-01-05 21:31:30,377 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 67%|██████▋   | 2/3 [00:16<00:07,  7.02s/it]2026-01-05 21:31:51,592 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 3/3 [00:38<00:00, 12.71s/it]\n",
      "2026-01-05 21:31:52,844 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_37596\\525095009.py:37: SyntaxWarning: \"\\g\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\g\"? A raw string is also an option.\n",
      "  FILE_PATH = \"D:\\git_rk\\data\\survey.csv\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_samples=3 should be >= n_clusters=5.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 142\u001b[39m\n\u001b[32m    140\u001b[39m N_CLUSTERS = \u001b[32m5\u001b[39m\n\u001b[32m    141\u001b[39m kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mcluster_id\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mkmeans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# 6. 클러스터 → 카테고리명 생성\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;66;03m############################################\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_cluster_name\u001b[39m(texts):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\git_rk\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1070\u001b[39m, in \u001b[36m_BaseKMeans.fit_predict\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1048\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[32m   1049\u001b[39m \n\u001b[32m   1050\u001b[39m \u001b[33;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1068\u001b[39m \u001b[33;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[32m   1069\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m.labels_\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\git_rk\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\git_rk\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1470\u001b[39m, in \u001b[36mKMeans.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1434\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[32m   1435\u001b[39m \n\u001b[32m   1436\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1458\u001b[39m \u001b[33;03m    Fitted estimator.\u001b[39;00m\n\u001b[32m   1459\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1460\u001b[39m X = validate_data(\n\u001b[32m   1461\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1462\u001b[39m     X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1467\u001b[39m     accept_large_sparse=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1468\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m random_state = check_random_state(\u001b[38;5;28mself\u001b[39m.random_state)\n\u001b[32m   1473\u001b[39m sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\git_rk\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1410\u001b[39m, in \u001b[36mKMeans._check_params_vs_input\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1409\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m-> \u001b[39m\u001b[32m1410\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_n_init\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28mself\u001b[39m._algorithm = \u001b[38;5;28mself\u001b[39m.algorithm\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._algorithm == \u001b[33m\"\u001b[39m\u001b[33melkan\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_clusters == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\git_rk\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:877\u001b[39m, in \u001b[36m_BaseKMeans._check_params_vs_input\u001b[39m\u001b[34m(self, X, default_n_init)\u001b[39m\n\u001b[32m    874\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, default_n_init=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    875\u001b[39m     \u001b[38;5;66;03m# n_clusters\u001b[39;00m\n\u001b[32m    876\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m X.shape[\u001b[32m0\u001b[39m] < \u001b[38;5;28mself\u001b[39m.n_clusters:\n\u001b[32m--> \u001b[39m\u001b[32m877\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    878\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mn_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m should be >= n_clusters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.n_clusters\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    881\u001b[39m     \u001b[38;5;66;03m# tol\u001b[39;00m\n\u001b[32m    882\u001b[39m     \u001b[38;5;28mself\u001b[39m._tol = _tolerance(X, \u001b[38;5;28mself\u001b[39m.tol)\n",
      "\u001b[31mValueError\u001b[39m: n_samples=3 should be >= n_clusters=5."
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# 0. 라이브러리 설치 (최초 1회)\n",
    "############################################\n",
    "\n",
    "!pip install -U openai pandas scikit-learn tqdm python-dotenv\n",
    "\n",
    "\n",
    "\n",
    "############################################\n",
    "# 1. 기본 설정\n",
    "############################################\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "import openai\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "if not openai.api_key:\n",
    "    logging.error(\"OpenAI API 키가 설정되어 있지 않습니다.\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "############################################\n",
    "# 2. CSV 로드\n",
    "############################################\n",
    "FILE_PATH = \"D:\\git_rk\\data\\survey.csv\"\n",
    "TEXT_COL = \"answer\"\n",
    "\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "df = df[df[TEXT_COL].notna()].copy()\n",
    "df.rename(columns={TEXT_COL: \"원본\"}, inplace=True)\n",
    "\n",
    "texts = df[\"원본\"].astype(str).tolist()\n",
    "print(f\"총 {len(texts)}건 주관식 응답 로드 완료\")\n",
    "\n",
    "\n",
    "############################################\n",
    "# 3. 원본 → 요약 (왜곡 금지)\n",
    "############################################\n",
    "def summarize_row(text):\n",
    "    prompt = f\"\"\"\n",
    "다음은 축제(행사)에 대한 설문 주관식 응답입니다.\n",
    "\n",
    "⚠️ 매우 중요:\n",
    "- 원문에 없는 내용은 절대 작성하지 마세요.\n",
    "- 추론, 일반화, 의미 확장 금지\n",
    "- '요약', '요약:' 같은 라벨이나 제목을 절대 출력하지 마세요.\n",
    "- 출력은 내용만 작성하세요.\n",
    "\n",
    "아래 응답에서\n",
    "응답자가 직접 언급한 핵심 내용만\n",
    "한 줄로 자연스럽게 정리해 주세요.\n",
    "\n",
    "설문 응답:\n",
    "{text}\n",
    "\n",
    "출력:\n",
    "\"\"\"\n",
    "    r = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"설문 응답 요약 전문가\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return r.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "summaries = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    for result in tqdm(executor.map(summarize_row, texts), total=len(texts)):\n",
    "        summaries.append(result)\n",
    "\n",
    "df[\"요약\"] = summaries\n",
    "\n",
    "\n",
    "############################################\n",
    "# 4. 요약 → 요약 개조식 (7단어 이내)\n",
    "############################################\n",
    "def bulletize_summary(summary):\n",
    "    prompt = f\"\"\"\n",
    "아래 문장은 설문 응답 요약 문장입니다.\n",
    "\n",
    "⚠️ 규칙:\n",
    "- 아래 문장에 등장한 단어와 표현만 사용\n",
    "- 새로운 단어, 의미, 해석 추가 금지\n",
    "- 단어 수는 최대 7개 이내\n",
    "- 조사 최소화\n",
    "- 라벨(요약, 정리 등) 출력 금지\n",
    "- 개조식 한 줄로만 출력\n",
    "\n",
    "요약 문장:\n",
    "{summary}\n",
    "\n",
    "출력:\n",
    "- \n",
    "\"\"\"\n",
    "    r = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"설문 요약 축약 전문가\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return r.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "bullet_summaries = []\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    for result in tqdm(executor.map(bulletize_summary, df[\"요약\"].tolist()), total=len(df)):\n",
    "        bullet_summaries.append(result)\n",
    "\n",
    "df[\"요약 개조식\"] = bullet_summaries\n",
    "\n",
    "\n",
    "############################################\n",
    "# 5. 요약 → 카테고리화 (임베딩 + 클러스터링)\n",
    "############################################\n",
    "def get_embeddings_batch(texts, model=\"text-embedding-3-small\", batch_size=50):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        r = client.embeddings.create(model=model, input=batch)\n",
    "        all_embeddings.extend([d.embedding for d in r.data])\n",
    "    return np.array(all_embeddings)\n",
    "\n",
    "summary_embeddings = get_embeddings_batch(df[\"요약\"].tolist())\n",
    "\n",
    "N_CLUSTERS = 5\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42)\n",
    "df[\"cluster_id\"] = kmeans.fit_predict(summary_embeddings)\n",
    "\n",
    "\n",
    "############################################\n",
    "# 6. 클러스터 → 카테고리명 생성\n",
    "############################################\n",
    "def generate_cluster_name(texts):\n",
    "    sample = \"\\n\".join(texts[:10])\n",
    "    prompt = f\"\"\"\n",
    "다음 요약 문장 묶음을 대표하는 카테고리명을 만들어 주세요.\n",
    "\n",
    "조건:\n",
    "- 요약 문장에 실제 등장한 표현 기반\n",
    "- 추론·확장 금지\n",
    "- 10자 내외 명사형\n",
    "\n",
    "요약 문장:\n",
    "{sample}\n",
    "\n",
    "출력:\n",
    "\"\"\"\n",
    "    r = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"설문 데이터 분류 전문가\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return r.choices[0].message.content.strip()\n",
    "\n",
    "cluster_names = {}\n",
    "for c in sorted(df[\"cluster_id\"].unique()):\n",
    "    texts_c = df[df[\"cluster_id\"] == c][\"요약\"].tolist()\n",
    "    cluster_names[c] = generate_cluster_name(texts_c)\n",
    "\n",
    "df[\"카테고리\"] = df[\"cluster_id\"].map(cluster_names)\n",
    "\n",
    "\n",
    "############################################\n",
    "# 7. 최종 산출물 저장\n",
    "############################################\n",
    "base_filename = os.path.splitext(os.path.basename(FILE_PATH))[0]\n",
    "now_str = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "excel_path = f\"data/{base_filename}_{now_str}.xlsx\"\n",
    "csv_path   = f\"data/{base_filename}_{now_str}.csv\"\n",
    "\n",
    "final_df = df[[\"원본\", \"요약\", \"요약 개조식\", \"카테고리\"]]\n",
    "display(final_df.head())\n",
    "\n",
    "final_df.to_excel(excel_path, index=False)\n",
    "final_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\n✅ 엑셀 저장 완료: {excel_path}\")\n",
    "print(f\"✅ CSV 저장 완료: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2844b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
