"""
PDF í†µí•© ì¶”ì¶œ ë° CSV ìµœì í™” ì €ì¥ ë§ˆìŠ¤í„° ì‹œìŠ¤í…œ (Windows ìµœì í™”)
- Excel ë¼ì´ë¸ŒëŸ¬ë¦¬ ì™„ì „ ë°°ì œ, CSV(utf-8-sig) ì¤‘ì‹¬ì˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸
- pdfplumber -> tabula-py ê²°í•¨ í—ˆìš©(Fault-tolerant) ì´ì¤‘ í´ë°± ì¶”ì¶œ
- ë§¤ë‹ˆí˜ìŠ¤íŠ¸(JSON) ë° ì½”ë“œ ìŠ¤ëƒ…ìƒ· ìë™ ë°±ì—…ì„ í†µí•œ 100% ë°ì´í„° ì¶”ì ì„± ë³´ì¥
"""

import os
import sys
import re
import json
import shutil
import hashlib
import datetime
import subprocess
import argparse
import tkinter as tk
from tkinter import filedialog
from pathlib import Path

try:
    import fitz  # PyMuPDF
    import pdfplumber
    import pandas as pd
    import tabula
except ImportError:
    print("âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”:")
    print("pip install PyMuPDF pdfplumber tabula-py pandas")
    sys.exit(1)

class PDFDocumentProcessor:
    def __init__(self, pdf_path, args):
        self.pdf_path = Path(pdf_path).resolve()
        self.args = args
        self.ts = datetime.datetime.now().strftime("%m%d%H%M")
        
        # Windows íŒŒì¼ëª… ì œì•½ íšŒí”¼ìš© Slugify ì²˜ë¦¬ (ìµœëŒ€ 80ì, ê¸ˆì§€ë¬¸ì ì œê±°)
        raw_name = self.pdf_path.stem
        slug = re.sub(r'[\\/*?:"<>|]', "", raw_name)
        slug = re.sub(r'\s+', "_", slug).strip("_")[:70]
        
        # íŒŒì¼ëª… ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•œ í•´ì‹œ ì ‘ë¯¸ì‚¬
        short_hash = hashlib.md5(self.pdf_path.name.encode()).hexdigest()[:4]
        self.slugified_name = f"{slug}_{short_hash}"
        self.doc_id = self.slugified_name
        
        # ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ êµ¬ì¡° ì„¤ê³„ (Exports í•˜ìœ„)
        self.base_dir = Path.cwd() / "Exports" / self.slugified_name
        self.dirs = {
            "Text": self.base_dir / "Text",
            "Tables_Index": self.base_dir / "Tables",
            "Tables_CSV": self.base_dir / "Tables" / "individual_csv",
            "Images_Embedded": self.base_dir / "Images" / "embedded",
            "Images_Rendered": self.base_dir / "Images" / "rendered",
            "Manifest": self.base_dir / "Manifest",
            "Backup": Path.cwd() / "GEMINI" / "code"
        }
        
        self.java_available = self._check_java()
        self.metadata_log = []
        self.tables_index = []
        self.page_count = 0
        self.scanned_suspect = False
        
        # ë Œë”ë§ ê²€ì‚¬ í‚¤ì›Œë“œ
        self.render_keywords = ["ê·¸ë¦¼", "ê·¸ë˜í”„", "ì°¨íŠ¸", "ë„í‘œ", "Figure", "Chart"]

    def _check_java(self):
        """Tabula-py ì‚¬ìš©ì„ ìœ„í•œ Java êµ¬ë™ í™˜ê²½ ë°±ê·¸ë¼ìš´ë“œ í™•ì¸"""
        try:
            subprocess.run(["java", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            return True
        except FileNotFoundError:
            print("âš ï¸ [ì‹œìŠ¤í…œ ì•Œë¦¼] Java í™˜ê²½ì´ ê°ì§€ë˜ì§€ ì•Šì•„ tabula-py í´ë°±ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            return False

    def _setup_directories_and_backup(self):
        """ë””ë ‰í† ë¦¬ ìƒì„± ë° ì‹¤í–‰ ì‹œì  ì½”ë“œ ìŠ¤ëƒ…ìƒ· ë°±ì—…"""
        for d in self.dirs.values():
            d.mkdir(parents=True, exist_ok=True)
            
        try:
            if '__file__' in globals():
                current_file = Path(__file__).resolve()
                backup_name = f"{current_file.stem}_{self.ts}{current_file.suffix}"
                shutil.copy2(current_file, self.dirs["Backup"] / backup_name)
        except Exception as e:
            print(f"  [Warning] ì½”ë“œ ë°±ì—… ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

    def _parse_render_pages(self, pages_str):
        """--render-pages '1,2,5-8' í˜•íƒœ íŒŒì‹±"""
        pages = set()
        if not pages_str:
            return pages
        for part in pages_str.split(','):
            part = part.strip()
            if '-' in part:
                try:
                    s, e = map(int, part.split('-'))
                    pages.update(range(s, e + 1))
                except ValueError:
                    pass
            elif part.isdigit():
                pages.add(int(part))
        return pages

    def _is_valid_table(self, table):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦: ìµœì†Œ 2x2, ë°ì´í„° ì±„ì›€ ë°€ë„ 20% ì´ìƒ í™•ì¸"""
        if not table or len(table) < 2:
            return False
            
        max_cols = max((len(r) for r in table if r), default=0)
        if max_cols < 2:
            return False
            
        total_cells = len(table) * max_cols
        filled_cells = sum(1 for r in table if r for c in r if c is not None and str(c).strip() != "")
        
        return (filled_cells / total_cells) >= 0.2

    def _normalize_table(self, table):
        """ë¶ˆê·œì¹™í•œ(ê°€ë³€ ê¸¸ì´) í‘œ í–‰ ì •ê·œí™” ì•Œê³ ë¦¬ì¦˜"""
        if not table: return []
        max_cols = max(len(r) for r in table if r)
        normalized = []
        for r in table:
            row = [str(c) if c is not None else "" for c in (r or [])]
            row += [""] * (max_cols - len(row))
            normalized.append(row)
        return normalized

    def _save_table(self, table_data, page_num, t_idx, method):
        """DataFrame ë³€í™˜ ë° CSV(utf-8-sig) ì €ì¥"""
        table_data = self._normalize_table(table_data)
        if len(table_data) < 2: return
        
        # ì¤‘ë³µ ì—†ëŠ” ì»¬ëŸ¼ëª… ìƒì„± ì²˜ë¦¬
        raw_cols = table_data[0]
        df_cols = []
        seen = set()
        for i, col in enumerate(raw_cols):
            base_col = str(col).strip().replace('\n', ' ') if col else f"Col_{i}"
            base_col = base_col if base_col else f"Col_{i}"
            
            final_col = base_col
            count = 1
            while final_col in seen:
                final_col = f"{base_col}_{count}"
                count += 1
            df_cols.append(final_col)
            seen.add(final_col)

        df = pd.DataFrame(table_data[1:], columns=df_cols)
        
        csv_name = f"table_p{page_num}_t{t_idx}_{method}_{self.ts}.csv"
        csv_path = self.dirs["Tables_CSV"] / csv_name
        
        # Windows Excel í˜¸í™˜ì„±ì„ ë³´ì¥í•˜ëŠ” utf-8-sig (BOM) ì¸ì½”ë”© ê°•ì œ
        df.to_csv(csv_path, index=False, encoding=self.args.csv_encoding)
        
        self.tables_index.append({
            "doc_id": self.doc_id, "ts": self.ts, "page": page_num,
            "table_idx": t_idx, "method": method,
            "csv_path": str(csv_path.relative_to(self.base_dir)),
            "rows": df.shape[0], "cols": df.shape[1]
        })
        
        self.metadata_log.append({
            "doc_id": self.doc_id, "ts": self.ts, "element_type": "table",
            "page": page_num, "method": method, "output_path": str(csv_path.relative_to(self.base_dir)),
            "bbox_unit(pt)": [], "coord_origin(top-left)": True
        })

    def run_pipeline(self):
        print(f"\nğŸš€ ë¶„ì„ ë° ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {self.pdf_path.name}")
        self._setup_directories_and_backup()
        
        full_text_lines = []
        total_text_length = 0
        render_pages_set = self._parse_render_pages(self.args.render_pages)
        
        # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ, ì´ë¯¸ì§€ ì„ë² ë”©, ê³ í•´ìƒë„ ë Œë”ë§ (PyMuPDF)
        with fitz.open(self.pdf_path) as doc:
            self.page_count = len(doc)
            for page_num in range(self.page_count):
                page = doc[page_num]
                page_height = page.rect.height
                
                # [í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ì œ]
                blocks = page.get_text("dict", sort=True)["blocks"]
                page_text_builder = []
                
                for b in blocks:
                    if b['type'] == 0:  # Text Block
                        y0, y1 = b["bbox"][1], b["bbox"][3]
                        block_text = "".join(s["text"] for l in b["lines"] for s in l["spans"])
                        
                        # ë¨¸ë¦¬ë§/ê¼¬ë¦¬ë§(Noise) ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ë¡œì§ (ìƒí•˜ë‹¨ 5% ë° ê¸¸ì´ 50ì ì´í•˜)
                        if (y0 < page_height * 0.05 or y1 > page_height * 0.95) and len(block_text) < 50:
                            continue
                            
                        block_text = re.sub(r'-\s*\n\s*', '', block_text).strip()  # í•˜ì´í”ˆ ì¤„ë°”ê¿ˆ ê²°í•©
                        
                        if block_text:
                            page_text_builder.append(block_text)
                            self.metadata_log.append({
                                "doc_id": self.doc_id, "ts": self.ts, "element_type": "text_block",
                                "page": page_num + 1, "method": "PyMuPDF", 
                                "output_path": f"Text/full_text_{self.ts}.txt",
                                "bbox_unit(pt)": [round(c, 2) for c in b["bbox"]], "coord_origin(top-left)": True
                            })
                            
                clean_page_text = "\n".join(page_text_builder)
                if clean_page_text:
                    full_text_lines.append(f"--- Page {page_num + 1} ---\n{clean_page_text}")
                    total_text_length += len(clean_page_text)

                # [ìˆœìˆ˜ ì´ë¯¸ì§€ ê°ì²´ ì¶”ì¶œ]
                for img_idx, img in enumerate(page.get_images(full=True)):
                    base_image = doc.extract_image(img[0])
                    img_path = self.dirs["Images_Embedded"] / f"img_p{page_num+1}_{img_idx+1}_{self.ts}.{base_image['ext']}"
                    with open(img_path, "wb") as f_img:
                        f_img.write(base_image["image"])

                # [í‚¤ì›Œë“œ ê°ì§€ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë Œë”ë§]
                has_keywords = any(kw in clean_page_text for kw in self.render_keywords)
                vectors = page.get_drawings()
                
                if self.args.render_all or ((page_num + 1) in render_pages_set) or has_keywords or len(vectors) >= 50:
                    pix = page.get_pixmap(dpi=300)
                    render_path = self.dirs["Images_Rendered"] / f"render_p{page_num+1}_{self.ts}.png"
                    pix.save(render_path)

        # ìŠ¤ìº”ë³¸ íŒë³„ (í‰ê·  50ì ë¯¸ë§Œ)
        if self.page_count > 0 and (total_text_length / self.page_count) < 50:
            self.scanned_suspect = True
            print("âš ï¸ [ê²½ê³ ] í…ìŠ¤íŠ¸ê°€ í˜„ì €íˆ ì ìŠµë‹ˆë‹¤. ìŠ¤ìº” ì´ë¯¸ì§€ ê¸°ë°˜ PDF(scanned_suspect)ë¡œ ì˜ì‹¬ë©ë‹ˆë‹¤.")

        # í†µí•© í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        with open(self.dirs["Text"] / f"full_text_{self.ts}.txt", "w", encoding="utf-8") as f:
            f.write("\n\n".join(full_text_lines))

        # 2. í‘œ(Table) ì¶”ì¶œ (pdfplumber + tabula-py ê²°í•¨ í—ˆìš© êµ¬ì¡°)
        print("ğŸ“Š í‘œ ë°ì´í„° êµ¬ì¡°í™” ë° ì´ì¤‘ í´ë°± ì²˜ë¦¬ ì¤‘...")
        with pdfplumber.open(self.pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages, start=1):
                tables = page.extract_tables()
                valid_tables_found = 0
                
                if tables:
                    for t_idx, table in enumerate(tables, start=1):
                        if self._is_valid_table(table):
                            self._save_table(table, page_num, valid_tables_found + 1, "pdfplumber")
                            valid_tables_found += 1
                            
                # í´ë°± ì‹œìŠ¤í…œ (pdfplumberê°€ ì‹¤íŒ¨í•˜ê±°ë‚˜ í’ˆì§ˆì´ ë¯¸ë‹¬ì¼ ë•Œ Tabula ê°œì…)
                if valid_tables_found == 0 and self.java_available:
                    try:
                        dfs = tabula.read_pdf(
                            self.pdf_path, pages=page_num, multiple_tables=True, 
                            guess=True, mode=self.args.tabula_mode,
                            pandas_options={'header': None, 'dtype': str} # ì²« í–‰ ë°ì´í„° ì†Œì‹¤ ë°©ì–´
                        )
                        for t_idx, df in enumerate(dfs):
                            df.fillna("", inplace=True)
                            table_list = df.values.tolist()
                            if self._is_valid_table(table_list):
                                self._save_table(table_list, page_num, valid_tables_found + 1, "tabula")
                                valid_tables_found += 1
                    except Exception:
                        pass
        
        self._generate_manifest()
        print(f"\nâœ… íŒŒì´í”„ë¼ì¸ êµ¬ë™ ì™„ë£Œ! ê²°ê³¼ë¬¼ì´ ë‹¤ìŒ ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\nğŸ“‚ {self.base_dir.resolve()}")


    def _generate_manifest(self):
        """ì‹¤í–‰ ì´ë ¥, íŒŒë¼ë¯¸í„° ìƒíƒœë¥¼ 100% ë³´ì¡´í•˜ëŠ” ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë°œê¸‰"""
        # CSV ì „ì²´ ì¸ë±ìŠ¤ ì €ì¥
        if self.tables_index:
            df_index = pd.DataFrame(self.tables_index)
            df_index.to_csv(self.dirs["Tables_Index"] / f"tables_index_{self.ts}.csv", index=False, encoding=self.args.csv_encoding)
            
        # ê°œë³„ ì¢Œí‘œ ë©”íƒ€ë°ì´í„° JSONL
        with open(self.dirs["Manifest"] / "metadata.jsonl", "w", encoding="utf-8") as f:
            for log in self.metadata_log:
                f.write(json.dumps(log, ensure_ascii=False) + "\n")
                
        # ì‹¤í–‰ í†µí•© ë§¤ë‹ˆí˜ìŠ¤íŠ¸ JSON
        run_manifest = {
            "doc_id": self.doc_id,
            "ts": self.ts,
            "source_pdf_path": str(self.pdf_path),
            "slugified_name": self.slugified_name,
            "page_count": self.page_count,
            "python_version": sys.version,
            "library_versions": {
                "PyMuPDF": fitz.VersionBind,
                "pdfplumber": pdfplumber.__version__,
                "pandas": pd.__version__,
                "tabula-py": tabula.__version__ if self.java_available else "Not Installed"
            },
            "args": vars(self.args),
            "render_policy": "selective_auto(keywords,vectors) or manual",
            "java_available": self.java_available,
            "scanned_suspect": self.scanned_suspect
        }
        with open(self.dirs["Manifest"] / "run_manifest.json", "w", encoding="utf-8") as f:
            json.dump(run_manifest, f, indent=4, ensure_ascii=False)


def select_file_gui():
    """Tkinterë¥¼ ì´ìš©í•œ ì§ê´€ì ì¸ ì‹œìŠ¤í…œ íŒŒì¼ ì„ íƒê¸°"""
    root = tk.Tk()
    root.withdraw()
    root.attributes('-topmost', True)
    
    file_path = filedialog.askopenfilename(
        title="ë°ì´í„°ë¥¼ ì¶”ì¶œí•  PDFë¥¼ ì„ íƒí•˜ì„¸ìš”",
        filetypes=[("PDF íŒŒì¼", "*.pdf"), ("ëª¨ë“  íŒŒì¼", "*.*")]
    )
    return file_path


def main():
    parser = argparse.ArgumentParser(description="PDF ë°ì´í„° ë¬´ì†ì‹¤ êµ¬ì¡°í™” ì‹œìŠ¤í…œ")
    parser.add_argument("--pdf", type=str, default="", help="ì²˜ë¦¬í•  PDF íŒŒì¼ ê²½ë¡œ (ë¯¸ì§€ì • ì‹œ íƒìƒ‰ê¸° ì°½ ì—´ë¦¼)")
    parser.add_argument("--layout", type=str, choices=["simple", "auto"], default="simple", help="í…ìŠ¤íŠ¸ ë‹¤ë‹¨ ë ˆì´ì•„ì›ƒ ëª¨ë“œ")
    parser.add_argument("--tabula-mode", type=str, choices=["stream", "lattice"], default="stream", help="Tabula í´ë°± ëª¨ë“œ")
    parser.add_argument("--render-all", action="store_true", help="ëª¨ë“  í˜ì´ì§€ ê°•ì œ ë Œë”ë§")
    parser.add_argument("--render-pages", type=str, default="", help="íŠ¹ì • í˜ì´ì§€ ë²”ìœ„ ì§€ì • ë Œë”ë§ (ì˜ˆ: 1,3,5-8)")
    parser.add_argument("--csv-encoding", type=str, choices=["utf-8-sig", "utf-8"], default="utf-8-sig", help="CSV ì €ì¥ ì¸ì½”ë”© í˜•ì‹")
    
    args = parser.parse_args()
    
    print("=" * 65)
    print(" ğŸ“‘ ë¡œì»¬ PDF ë¹„ì •í˜• ë°ì´í„° ì •ë°€ ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ (Windows) ")
    print("=" * 65)
    
    pdf_path = args.pdf
    if not pdf_path:
        print("ğŸ’¡ ë¶„ì„í•  PDFë¥¼ ì‹œìŠ¤í…œ íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ ì„ íƒí•´ ì£¼ì„¸ìš”...")
        pdf_path = select_file_gui()
        
    if not pdf_path or not os.path.exists(pdf_path):
        print("âŒ ìœ íš¨í•œ PDFê°€ ì„ íƒë˜ì§€ ì•Šì•„ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        sys.exit(0)
        
    processor = PDFDocumentProcessor(pdf_path, args)
    processor.run_pipeline()


if __name__ == "__main__":
    main()