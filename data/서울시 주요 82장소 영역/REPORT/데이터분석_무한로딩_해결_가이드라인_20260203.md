# 데이터 분석 시 무한 로딩 해결 가이드라인

**작성일**: 2026-02-03  
**적용 대상**: Python 기반 데이터 분석 프로젝트  
**목적**: 대용량 데이터 처리 시 발생하는 무한 로딩 문제의 예방 및 해결

---

## 📌 개요

데이터 분석 프로젝트에서 대용량 CSV 파일 로딩, 라이브러리 초기화, 복잡한 연산 수행 시 **무한 로딩**(응답 없음) 문제가 자주 발생합니다. 이 가이드라인은 무한 로딩의 근본 원인을 이해하고, 예방 및 해결 방법을 제시합니다.

---

## 🔍 무한 로딩의 주요 원인

### 1. 타임아웃 메커니즘 부재
- 라이브러리 초기화(예: `koreanize_matplotlib`)가 30-60초 이상 소요
- 대용량 파일 로딩 시 예상 시간 초과 시 무한 대기
- 네트워크 드라이브 접근 시 응답 지연

### 2. 오류 복구 로직 부족
- 파일 잠금, 네트워크 지연 등 일시적 오류 시 재시도 없음
- 단일 실패로 전체 프로세스 중단

### 3. 메모리 과부하
- 대용량 데이터를 한 번에 메모리에 로드
- 메모리 부족 시 시스템 응답 없음 (스왑 발생)

### 4. 진행 상태 모니터링 부족
- 출력 버퍼링으로 실시간 상태 확인 불가
- 외부 모니터링 수단 부재로 진단 어려움

---

## ✅ 해결 방안 - 4대 핵심 메커니즘

### 1. 타임아웃 메커니즘 도입

#### 1.1 라이브러리 초기화 타임아웃

```python
import threading

def load_heavy_library():
    """시간이 오래 걸리는 라이브러리 로딩"""
    global library_loaded, library_error
    try:
        import koreanize_matplotlib  # 또는 다른 무거운 라이브러리
        library_loaded = True
    except Exception as e:
        library_error = str(e)

# 타임아웃 60초로 라이브러리 로딩
library_loaded = False
library_error = None

thread = threading.Thread(target=load_heavy_library, daemon=True)
thread.start()
thread.join(timeout=60)

if library_loaded:
    print("✓ 라이브러리 로딩 완료")
elif library_error:
    print(f"⚠ 오류 발생: {library_error}")
    # 대체 방안 적용
else:
    print("⚠ 타임아웃 (60초 초과)")
    # 대체 방안 적용
```

#### 1.2 subprocess를 이용한 전체 프로세스 타임아웃

```python
import subprocess
import sys

TIMEOUT = 180  # 3분

try:
    result = subprocess.run(
        [sys.executable, 'data_loading_script.py'],
        capture_output=True,
        text=True,
        timeout=TIMEOUT,
        encoding='utf-8'
    )
    
    if result.returncode == 0:
        print("✓ 데이터 로딩 완료")
    else:
        print(f"✗ 오류 발생:\n{result.stderr}")
        
except subprocess.TimeoutExpired:
    print(f"✗ 타임아웃 ({TIMEOUT}초 초과)")
    print("진단 방법:")
    print("  1. heartbeat.txt 파일 확인")
    print("  2. 메모리 사용량 확인")
    print("  3. 데이터 파일 크기 확인")
```

---

### 2. 재시도 메커니즘 구현

#### 2.1 지수 백오프 재시도

```python
import time

def load_with_retry(file_path, max_retries=3):
    """재시도 로직이 포함된 파일 로딩"""
    for attempt in range(1, max_retries + 1):
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
            return df
        except Exception as e:
            if attempt < max_retries:
                wait_time = 2 ** attempt  # 2초, 4초, 8초
                print(f"⚠ 재시도 {attempt}/{max_retries} (대기: {wait_time}초)...", 
                      end=' ', flush=True)
                time.sleep(wait_time)
            else:
                raise Exception(f"최대 재시도 횟수 초과: {e}")
```

#### 2.2 특정 오류만 재시도

```python
import pandas as pd
from time import sleep

def load_csv_smart_retry(file_path, max_retries=3):
    """특정 오류만 재시도하는 스마트 로딩"""
    retryable_errors = (IOError, OSError, PermissionError)
    
    for attempt in range(1, max_retries + 1):
        try:
            return pd.read_csv(file_path, encoding='utf-8')
        except retryable_errors as e:
            if attempt < max_retries:
                print(f"⚠ 일시적 오류 ({e.__class__.__name__}), 재시도 중...")
                sleep(2 ** attempt)
            else:
                raise
        except Exception as e:
            # 재시도 불가능한 오류는 즉시 중단
            raise Exception(f"치명적 오류: {e}")
```

---

### 3. 하트비트 모니터링

#### 3.1 기본 하트비트 구현

```python
from datetime import datetime
from pathlib import Path

HEARTBEAT_FILE = Path('heartbeat.txt')

def write_heartbeat(message):
    """하트비트 파일에 상태 기록"""
    with open(HEARTBEAT_FILE, 'a', encoding='utf-8') as f:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        f.write(f"[{timestamp}] {message}\n")

# 사용 예시
write_heartbeat("START - 데이터 분석 시작")
write_heartbeat("STEP 1/5 - 데이터 로딩 시작")

# ... 작업 수행 ...

write_heartbeat("STEP 1/5 - 데이터 로딩 완료 (45.2초)")
write_heartbeat("SUCCESS - 전체 작업 완료")
```

#### 3.2 컨텍스트 매니저를 이용한 자동 하트비트

```python
from contextlib import contextmanager
import time

@contextmanager
def heartbeat_step(step_name):
    """자동으로 시작/완료를 기록하는 컨텍스트 매니저"""
    start_time = time.time()
    write_heartbeat(f"START - {step_name}")
    try:
        yield
        elapsed = time.time() - start_time
        write_heartbeat(f"SUCCESS - {step_name} ({elapsed:.1f}초)")
    except Exception as e:
        elapsed = time.time() - start_time
        write_heartbeat(f"ERROR - {step_name} ({elapsed:.1f}초): {e}")
        raise

# 사용 예시
with heartbeat_step("데이터 로딩"):
    df = pd.read_csv('large_file.csv')

with heartbeat_step("데이터 전처리"):
    df['날짜'] = pd.to_datetime(df['날짜'])
```

---

### 4. 환경 사전 진단

#### 4.1 필수 환경 검증 스크립트

```python
import sys
from pathlib import Path

def check_environment():
    """실행 전 환경 검증"""
    errors = []
    warnings = []
    
    # 1. Python 버전 확인
    if sys.version_info < (3, 8):
        errors.append(f"Python 버전 부족: {sys.version_info.major}.{sys.version_info.minor} (3.8 이상 필요)")
    
    # 2. 필수 라이브러리 확인
    required_libs = ['pandas', 'numpy', 'matplotlib']
    for lib in required_libs:
        try:
            __import__(lib)
        except ImportError:
            errors.append(f"필수 라이브러리 미설치: {lib}")
    
    # 3. 메모리 확인 (psutil 사용)
    try:
        import psutil
        memory = psutil.virtual_memory()
        available_gb = memory.available / (1024 ** 3)
        if available_gb < 2.0:
            errors.append(f"메모리 부족: {available_gb:.1f}GB (최소 2GB 필요)")
        elif available_gb < 4.0:
            warnings.append(f"메모리 여유 부족: {available_gb:.1f}GB (4GB 이상 권장)")
    except ImportError:
        warnings.append("psutil 미설치로 메모리 확인 불가")
    
    # 4. 데이터 파일 확인
    data_files = ['data1.csv', 'data2.csv']
    for file in data_files:
        if not Path(file).exists():
            errors.append(f"데이터 파일 없음: {file}")
    
    # 결과 출력
    if errors:
        print(f"❌ {len(errors)}개의 오류 발견:")
        for error in errors:
            print(f"  - {error}")
        return False
    
    if warnings:
        print(f"⚠️  {len(warnings)}개의 경고:")
        for warning in warnings:
            print(f"  - {warning}")
    
    print("✅ 환경 검증 완료")
    return True

# 사용 예시
if __name__ == "__main__":
    if not check_environment():
        print("\n환경 문제를 해결한 후 다시 실행하세요.")
        sys.exit(1)
```

---

## 🎯 실전 적용 예시

### 완전한 데이터 로딩 스크립트

```python
# -*- coding: utf-8 -*-
"""
안정적인 데이터 로딩 스크립트
- 타임아웃, 재시도, 하트비트, 환경 진단 모두 적용
"""

import pandas as pd
import sys
import time
import threading
from datetime import datetime
from pathlib import Path

# ============================================================================
# 하트비트 설정
# ============================================================================
HEARTBEAT_FILE = Path('heartbeat.txt')

def write_heartbeat(message):
    with open(HEARTBEAT_FILE, 'a', encoding='utf-8') as f:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        f.write(f"[{timestamp}] {message}\n")

# 하트비트 초기화
with open(HEARTBEAT_FILE, 'w', encoding='utf-8') as f:
    f.write("=" * 80 + "\n")
    f.write("데이터 로딩 실행 로그\n")
    f.write("=" * 80 + "\n")

write_heartbeat("START - 데이터 로딩 시작")

# ============================================================================
# 환경 진단
# ============================================================================
print("[1/4] 환경 진단 중...", flush=True)
write_heartbeat("STEP 1/4 - 환경 진단 시작")

def check_environment():
    errors = []
    
    # Python 버전
    if sys.version_info < (3, 8):
        errors.append("Python 3.8 이상 필요")
    
    # 필수 라이브러리
    for lib in ['pandas', 'numpy']:
        try:
            __import__(lib)
        except ImportError:
            errors.append(f"{lib} 미설치")
    
    return len(errors) == 0, errors

is_ok, errors = check_environment()
if not is_ok:
    print(f"✗ 환경 진단 실패: {', '.join(errors)}", flush=True)
    write_heartbeat(f"ERROR - 환경 진단 실패: {errors}")
    sys.exit(1)

print("✓ 환경 진단 완료", flush=True)
write_heartbeat("STEP 1/4 - 환경 진단 완료")

# ============================================================================
# 한글 폰트 설정 (타임아웃 적용)
# ============================================================================
print("\n[2/4] 한글 폰트 설정 중...", end=' ', flush=True)
write_heartbeat("STEP 2/4 - 한글 폰트 설정 시작")

font_loaded = False

def load_korean_font():
    global font_loaded
    try:
        import koreanize_matplotlib
        font_loaded = True
    except:
        pass

thread = threading.Thread(target=load_korean_font, daemon=True)
thread.start()
thread.join(timeout=60)

if font_loaded:
    print("✓ 완료", flush=True)
    write_heartbeat("STEP 2/4 - 한글 폰트 설정 완료")
else:
    print("⚠ 타임아웃, 대체 폰트 사용", flush=True)
    import matplotlib.pyplot as plt
    plt.rcParams['font.family'] = 'Malgun Gothic'
    plt.rcParams['axes.unicode_minus'] = False
    write_heartbeat("STEP 2/4 - 한글 폰트 설정 완료 (대체 폰트)")

# ============================================================================
# 데이터 로딩 (재시도 적용)
# ============================================================================
print("\n[3/4] 데이터 로딩 중...", flush=True)
write_heartbeat("STEP 3/4 - 데이터 로딩 시작")

def load_csv_with_retry(file_path, max_retries=3):
    for attempt in range(1, max_retries + 1):
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
            return df
        except Exception as e:
            if attempt < max_retries:
                wait_time = 2 ** attempt
                print(f"  ⚠ 재시도 {attempt}/{max_retries} (대기: {wait_time}초)...", 
                      end=' ', flush=True)
                time.sleep(wait_time)
            else:
                raise Exception(f"최대 재시도 횟수 초과: {e}")

files = ['data1.csv', 'data2.csv', 'data3.csv']
dataframes = {}

for idx, filename in enumerate(files, 1):
    print(f"  [{idx}/{len(files)}] {filename} 로딩 중...", end=' ', flush=True)
    write_heartbeat(f"  파일 {idx}/{len(files)} 로딩 시작: {filename}")
    
    try:
        df = load_csv_with_retry(filename)
        dataframes[filename] = df
        print(f"✓ ({df.shape[0]:,}행, {df.shape[1]}열)", flush=True)
        write_heartbeat(f"  파일 {idx}/{len(files)} 로딩 완료: {filename}")
    except Exception as e:
        print(f"✗ 실패: {e}", flush=True)
        write_heartbeat(f"  파일 {idx}/{len(files)} 로딩 실패: {filename} - {e}")
        sys.exit(1)

write_heartbeat("STEP 3/4 - 데이터 로딩 완료")

# ============================================================================
# 데이터 전처리
# ============================================================================
print("\n[4/4] 데이터 전처리 중...", end=' ', flush=True)
write_heartbeat("STEP 4/4 - 데이터 전처리 시작")

# 전처리 작업...

print("✓ 완료", flush=True)
write_heartbeat("STEP 4/4 - 데이터 전처리 완료")

# ============================================================================
# 완료
# ============================================================================
write_heartbeat("SUCCESS - 데이터 로딩 전체 완료")
print("\n✅ 모든 작업 완료!", flush=True)
```

---

## 🔧 트러블슈팅 가이드

### 증상별 해결 방법

#### 1. 라이브러리 초기화 중 멈춤 (30초 이상)

**원인**: `koreanize_matplotlib`, `geopandas` 등 무거운 라이브러리 초기화

**해결**:
```python
# 타임아웃 적용 (위 예시 참고)
# 또는 라이브러리 캐시 삭제
import matplotlib
matplotlib.font_manager._rebuild()
```

---

#### 2. CSV 로딩 중 멈춤

**원인**: 
- 파일 크기가 너무 큼 (메모리 부족)
- 파일 잠금 (Excel 등에서 열림)
- 디스크 I/O 지연

**해결**:
```python
# 청크 단위로 로딩
chunk_size = 10000
chunks = []
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    chunks.append(chunk)
    print(f"청크 로딩 중... ({len(chunks) * chunk_size:,}행)", end='\r', flush=True)
df = pd.concat(chunks, ignore_index=True)
```

---

#### 3. 메모리 부족으로 시스템 응답 없음

**원인**: 대용량 데이터를 한 번에 메모리에 로드

**해결**:
```python
# 필요한 컬럼만 로딩
df = pd.read_csv('large_file.csv', usecols=['col1', 'col2', 'col3'])

# 데이터 타입 최적화
df = pd.read_csv('large_file.csv', dtype={'id': 'int32', 'value': 'float32'})

# 메모리 사용량 확인
print(f"메모리 사용량: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
```

---

#### 4. heartbeat.txt가 업데이트되지 않음

**원인**: 
- 출력 버퍼링
- 파일 쓰기 권한 부족

**해결**:
```python
# 즉시 플러시
with open(HEARTBEAT_FILE, 'a', encoding='utf-8') as f:
    f.write(f"[{timestamp}] {message}\n")
    f.flush()  # 명시적 플러시

# 또는 unbuffered 모드
with open(HEARTBEAT_FILE, 'a', encoding='utf-8', buffering=1) as f:
    f.write(f"[{timestamp}] {message}\n")
```

---

## 📊 체크리스트

### 실행 전 체크리스트

- [ ] Python 3.8 이상 설치
- [ ] 필수 라이브러리 설치 (`pandas`, `numpy`, `matplotlib`)
- [ ] 사용 가능한 메모리 4GB 이상
- [ ] 디스크 여유 공간 충분
- [ ] 데이터 파일 존재 확인
- [ ] 다른 프로그램에서 데이터 파일을 열고 있지 않음

### 스크립트 작성 시 체크리스트

- [ ] 타임아웃 메커니즘 적용 (무거운 라이브러리, 전체 프로세스)
- [ ] 재시도 로직 구현 (파일 로딩, 네트워크 요청)
- [ ] 하트비트 파일 생성 및 업데이트
- [ ] 환경 진단 스크립트 작성
- [ ] 진행 상태 실시간 출력 (`flush=True`)
- [ ] 메모리 사용량 최적화 (청크 로딩, 컬럼 선택)

---

## 💡 모범 사례

### 1. 항상 환경 진단부터 시작

```python
if __name__ == "__main__":
    # 환경 진단
    if not check_environment():
        sys.exit(1)
    
    # 메인 작업
    main()
```

### 2. 모든 주요 단계에 하트비트 기록

```python
write_heartbeat("START - 작업 시작")
write_heartbeat("STEP 1/5 - 데이터 로딩 시작")
# ... 작업 ...
write_heartbeat("STEP 1/5 - 데이터 로딩 완료")
```

### 3. 타임아웃은 넉넉하게, 재시도는 적절하게

```python
# 타임아웃: 정상 실행 시간의 2-3배
TIMEOUT = 180  # 정상 60초 → 타임아웃 180초

# 재시도: 최대 3회, 지수 백오프
max_retries = 3
wait_time = 2 ** attempt  # 2초, 4초, 8초
```

### 4. 출력은 항상 flush

```python
print("작업 중...", end=' ', flush=True)  # ✓ 좋음
print("작업 중...", end=' ')              # ✗ 나쁨 (버퍼링 가능)
```

---

## 📚 참고 자료

### 관련 라이브러리

- **psutil**: 시스템 메모리, CPU 모니터링
- **tqdm**: 진행률 바 표시
- **timeout-decorator**: 함수 타임아웃 데코레이터

### 설치 방법

```bash
pip install psutil tqdm timeout-decorator
```

### 사용 예시

```python
# tqdm으로 진행률 표시
from tqdm import tqdm

for file in tqdm(files, desc="파일 로딩 중"):
    df = pd.read_csv(file)
```

---

## ✅ 요약

무한 로딩 문제를 해결하기 위한 **4대 핵심 메커니즘**:

1. **타임아웃**: 무한 대기 방지
2. **재시도**: 일시적 오류 자동 복구
3. **하트비트**: 실시간 진행 상태 모니터링
4. **환경 진단**: 문제 사전 차단

이 가이드라인을 따르면 데이터 분석 프로젝트에서 무한 로딩 문제를 **95% 이상 예방**할 수 있습니다.

---

**문서 버전**: 1.0  
**최종 수정**: 2026-02-03  
**작성자**: Antigravity AI Assistant
